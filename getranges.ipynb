{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd295e1",
   "metadata": {},
   "source": [
    "### NOTE! HASHTAGGED CELLS THAT HAVE FORMULAS SHOULD  HAVE THE # REMOVED BEFORE RUNNING *security reasons*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31bf747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Tue Apr  6 17:35:01 2021\n",
    "\n",
    "@author: schne\n",
    "\"\"\"\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from __future__ import print_function\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "import email\n",
    "import base64\n",
    "import requests\n",
    "import itertools\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "\n",
    "\n",
    "def search_inbox(service, user_id,search_string):\n",
    "    \"\"\"\n",
    "    Search the inbox for emails using standard gmail search parameters\n",
    "    and return a list of email IDs for each result\n",
    "    PARAMS:\n",
    "        service: the google api service object already instantiated\n",
    "        user_id: user id for google api service ('me' works here if\n",
    "        already authenticated)\n",
    "        search_string: search operators you can use with Gmail\n",
    "        (see https://support.google.com/mail/answer/7190?hl=en for a list)\n",
    "    RETURNS:\n",
    "        List containing email IDs of search query\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # initiate the list for returning\n",
    "        list_ids = []\n",
    "\n",
    "        # get the id of all messages that are in the search string\n",
    "        search_ids = service.users().messages().list(userId=user_id,labelIds='INBOX', q=search_string).execute()\n",
    "        \n",
    "        # if there were no results, print warning and return empty string\n",
    "        try:\n",
    "            ids = search_ids['messages']\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"WARNING: the search queried returned 0 results\")\n",
    "            print(\"returning an empty string\")\n",
    "            return \"\"\n",
    "\n",
    "        if len(ids)>1:\n",
    "            for msg_id in ids:\n",
    "                list_ids.append(msg_id['id'])\n",
    "            return(list_ids)\n",
    "\n",
    "        else:\n",
    "            list_ids.append(ids['id'])\n",
    "            return list_ids\n",
    "        \n",
    "    except (errors.HttpError, error):\n",
    "        print(\"An error occured: %s\") % error\n",
    "        \n",
    "        \n",
    "def get_message(service, user_id, msg_id):\n",
    "    \"\"\"\n",
    "    Search the inbox for specific message by ID and return it back as a \n",
    "    clean string. String may contain Python escape characters for newline\n",
    "    and return line. \n",
    "    \n",
    "    PARAMS\n",
    "        service: the google api service object already instantiated\n",
    "        user_id: user id for google api service ('me' works here if\n",
    "        already authenticated)\n",
    "        msg_id: the unique id of the email you need\n",
    "    RETURNS\n",
    "        A string of encoded text containing the message body\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # grab the message instance\n",
    "        message = service.users().messages().get(userId=user_id, id=msg_id,format='raw').execute()\n",
    "\n",
    "        # decode the raw string, ASCII works pretty well here\n",
    "        msg_str = base64.urlsafe_b64decode(message['raw'].encode('ASCII'))\n",
    "\n",
    "        # grab the string from the byte object\n",
    "        mime_msg = email.message_from_bytes(msg_str)\n",
    "\n",
    "        # check if the content is multipart (it usually is)\n",
    "        content_type = mime_msg.get_content_maintype()\n",
    "        if content_type == 'multipart':\n",
    "            # there will usually be 2 parts the first will be the body in text\n",
    "            # the second will be the text in html\n",
    "            parts = mime_msg.get_payload()\n",
    "\n",
    "            # return the encoded text\n",
    "            final_content = parts[0].get_payload()\n",
    "            return final_content\n",
    "\n",
    "        elif content_type == 'text':\n",
    "            return mime_msg.get_payload()\n",
    "\n",
    "        else:\n",
    "            return \"\"\n",
    "            print(\"\\nMessage is not text or multipart, returned an empty string\")\n",
    "    # unsure why the usual exception doesn't work in this case, but \n",
    "    # having a standard Exception seems to do the trick\n",
    "    except Exception:\n",
    "        print(\"An error occured: %s\") % error\n",
    "\n",
    "\n",
    "def get_service():\n",
    "    \"\"\"\n",
    "    Authenticate the google api client and return the service object \n",
    "    to make further calls\n",
    "    PARAMS\n",
    "        None\n",
    "    RETURNS\n",
    "        service api object from gmail for making calls\n",
    "    \"\"\"\n",
    "    \n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "    # Call the Gmail API\n",
    "    results = service.users().labels().list(userId='me').execute()\n",
    "    labels = results.get('labels', [])\n",
    "\n",
    "    return service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1fc263",
   "metadata": {},
   "source": [
    "### Method to Scrape Risk Range Table from the Hedgeye website (currently unable to use as no HTTP access :(\n",
    "\n",
    "r = requests.get(\"https://app.hedgeye.com/users/sign_in\", auth=('', ''))\n",
    "\n",
    "r\n",
    "\n",
    "r.headers['content-type']\n",
    "\n",
    "r.encoding\n",
    "\n",
    "r.text\n",
    "\n",
    "s = requests.get('')\n",
    "\n",
    "s.text\n",
    "\n",
    "soup3=BeautifulSoup(r,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4379df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check labels on GMAIL. This is to ensure we only select the correct Label folder ('INBOX') for the message pull\n",
    "#service.users().labels().list(userId='me', x__xgafv=None).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "543e59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check labels on GMAIL. This is to ensure we only select the correct Label folder ('INBOX') for the message pull\n",
    "#service.users().messages().list(userId='me',labelIds='INBOX', x__xgafv=None).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7a4f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['178c5d1ab177f6ab',\n",
       " '178b675562417123',\n",
       " '178b166d5d3bed46',\n",
       " '178ac35ef5b46790',\n",
       " '178a7188cb49c5ae',\n",
       " '178a1f2520c7d299',\n",
       " '1788d4e06e8efd8f',\n",
       " '178882dc6ba33b38',\n",
       " '17882fe62d70cb4a',\n",
       " '1787dcf1ca93c3b2',\n",
       " '1786e624bc818228',\n",
       " '1786946ed378be54',\n",
       " '1786417c71c9df57',\n",
       " '1785ef15e49e0838',\n",
       " '17859c8091567e0f',\n",
       " '1784a47b8ac0fab4',\n",
       " '178453d33b1972e9',\n",
       " '17840163c9aaa5dc',\n",
       " '1783af6421a6d9cb',\n",
       " '17835bf5fd97d5b3',\n",
       " '17826a85ca0f473a',\n",
       " '178215f1ee928c6e',\n",
       " '17811e4c42f60a44',\n",
       " '177fd49f83332420',\n",
       " '177f827fd8a707e4',\n",
       " '177f31193a68d85d',\n",
       " '177ede2898bb1f8a',\n",
       " '177de7542c8d39ee']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service=get_service()\n",
    "rr_emails=search_inbox(service,'me',\"CLICK HERE to submit up to 4 tickers you'd like to see on the list.\")\n",
    "rr_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb2adaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_rr_emails=list(iter(range(len(rr_emails))))\n",
    "\n",
    "\n",
    "email_series=pd.Series(rr_emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6fc9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'178c5d1ab177f6ab': None, '178b675562417123': None, '178b166d5d3bed46': None, '178ac35ef5b46790': None, '178a7188cb49c5ae': None, '178a1f2520c7d299': None, '1788d4e06e8efd8f': None, '178882dc6ba33b38': None, '17882fe62d70cb4a': None, '1787dcf1ca93c3b2': None, '1786e624bc818228': None, '1786946ed378be54': None, '1786417c71c9df57': None, '1785ef15e49e0838': None, '17859c8091567e0f': None, '1784a47b8ac0fab4': None, '178453d33b1972e9': None, '17840163c9aaa5dc': None, '1783af6421a6d9cb': None, '17835bf5fd97d5b3': None, '17826a85ca0f473a': None, '178215f1ee928c6e': None, '17811e4c42f60a44': None, '177fd49f83332420': None, '177f827fd8a707e4': None, '177f31193a68d85d': None, '177ede2898bb1f8a': None, '177de7542c8d39ee': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['178c5d1ab177f6ab', '178b675562417123', '178b166d5d3bed46', '178ac35ef5b46790', '178a7188cb49c5ae', '178a1f2520c7d299', '1788d4e06e8efd8f', '178882dc6ba33b38', '17882fe62d70cb4a', '1787dcf1ca93c3b2', '1786e624bc818228', '1786946ed378be54', '1786417c71c9df57', '1785ef15e49e0838', '17859c8091567e0f', '1784a47b8ac0fab4', '178453d33b1972e9', '17840163c9aaa5dc', '1783af6421a6d9cb', '17835bf5fd97d5b3', '17826a85ca0f473a', '178215f1ee928c6e', '17811e4c42f60a44', '177fd49f83332420', '177f827fd8a707e4', '177f31193a68d85d', '177ede2898bb1f8a', '177de7542c8d39ee'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary of email lists \n",
    "# using list comprehension \n",
    "\n",
    "rr_dict = dict((val, None) for val in rr_emails) \n",
    "\n",
    "print(rr_dict) \n",
    "rr_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb03c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT RUN THIS CODE AFTER FIRST PARSING!!! WILL RERUN WHOLE API GET AND POTENTIALLY INCUR UNWANTED CALL FEES!\n",
    "\n",
    "#with open('data_pick.pkl','wb') as pickle_file:\n",
    "    #pickle.dump(rr_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c97af9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'178c5d1ab177f6ab': None,\n",
       " '178b675562417123': None,\n",
       " '178b166d5d3bed46': None,\n",
       " '178ac35ef5b46790': None,\n",
       " '178a7188cb49c5ae': None,\n",
       " '178a1f2520c7d299': None,\n",
       " '1788d4e06e8efd8f': None,\n",
       " '178882dc6ba33b38': None,\n",
       " '17882fe62d70cb4a': None,\n",
       " '1787dcf1ca93c3b2': None,\n",
       " '1786e624bc818228': None,\n",
       " '1786946ed378be54': None,\n",
       " '1786417c71c9df57': None,\n",
       " '1785ef15e49e0838': None,\n",
       " '17859c8091567e0f': None,\n",
       " '1784a47b8ac0fab4': None,\n",
       " '178453d33b1972e9': None,\n",
       " '17840163c9aaa5dc': None,\n",
       " '1783af6421a6d9cb': None,\n",
       " '17835bf5fd97d5b3': None,\n",
       " '17826a85ca0f473a': None,\n",
       " '178215f1ee928c6e': None,\n",
       " '17811e4c42f60a44': None,\n",
       " '177fd49f83332420': None,\n",
       " '177f827fd8a707e4': None,\n",
       " '177f31193a68d85d': None,\n",
       " '177ede2898bb1f8a': None,\n",
       " '177de7542c8d39ee': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hey Morty, I turned myself into a pickle! im_pkl_dict!!    \n",
    "with open('data_pick.pkl','rb') as pickle_file:\n",
    "    im_pkl_dict=pickle.load(pickle_file)\n",
    "\n",
    "im_pkl_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3981b28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Risk Range Emails have been pulled\n"
     ]
    }
   ],
   "source": [
    "###Add New Keys with each run\n",
    "\n",
    "for val in list(rr_emails):  # Use a list instead of a view\n",
    "    if val not in im_pkl_dict.keys():\n",
    "        im_pkl_dict.update((val, None ))\n",
    "print('All Risk Range Emails have been pulled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6513c3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n",
      "Message Successfully Pulled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['178c5d1ab177f6ab', '178b675562417123', '178b166d5d3bed46', '178ac35ef5b46790', '178a7188cb49c5ae', '178a1f2520c7d299', '1788d4e06e8efd8f', '178882dc6ba33b38', '17882fe62d70cb4a', '1787dcf1ca93c3b2', '1786e624bc818228', '1786946ed378be54', '1786417c71c9df57', '1785ef15e49e0838', '17859c8091567e0f', '1784a47b8ac0fab4', '178453d33b1972e9', '17840163c9aaa5dc', '1783af6421a6d9cb', '17835bf5fd97d5b3', '17826a85ca0f473a', '178215f1ee928c6e', '17811e4c42f60a44', '177fd49f83332420', '177f827fd8a707e4', '177f31193a68d85d', '177ede2898bb1f8a', '177de7542c8d39ee'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add Message to Values in Dictionary\n",
    "for key, val in im_pkl_dict.items():\n",
    "    if val == None:\n",
    "        msg = get_message(service,'me',key)\n",
    "        thisdict= dict((key, msg) for val in list(im_pkl_dict.values()))\n",
    "        im_pkl_dict.update(thisdict)\n",
    "        print(\"Message Successfully Pulled\")\n",
    "    else:\n",
    "    \n",
    "        print(\"Already Pulled\")\n",
    "\n",
    "#print(im_pkl_dict)\n",
    "\n",
    "        \n",
    "\n",
    "# Easy way to check if data came through because of the size of dictionary values returned\n",
    "im_pkl_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e136d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickle the file again to new pkl file\n",
    "with open('im_pkl_dict.pkl','wb') as pickle_file:\n",
    "    pickle.dump(im_pkl_dict, pickle_file)\n",
    "\n",
    "    \n",
    "with open('im_pkl_dict.pkl','rb') as pickle_file:\n",
    "    im_pkl_dict=pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1f91295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-8bd67882cc45>:87: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  raw=raw.str.replace(r\"(?<=[liP]) (?=\\d)\",'') ## searching for first instances of '1 str' + ' ' + '1 int'\n",
      "<ipython-input-15-8bd67882cc45>:88: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  raw=raw.str.replace(r\"(?<=\\d) (?=[I])\",'') ## Regex specific to Nikkei 225 Index\n"
     ]
    }
   ],
   "source": [
    "#Code to format each email message str pull and apply formatted results (a DataFrame) into a list of DataFrame, then append list to new df\n",
    "\n",
    "##The new df to which formatted dataframe data (final_df) will be appended to.\n",
    "rr_dfs=pd.DataFrame(columns=['Asset','LERR','TERR','LastPrice','Trend','Ticker','Date']).reset_index(drop=True)\n",
    "rr_dfs\n",
    "\n",
    "#The list of dataframes\n",
    "appended_data=[]\n",
    "\n",
    "for val in list(im_pkl_dict.values()):\n",
    "    ## Beautiful Soup\n",
    "    soup = BeautifulSoup(val, 'lxml')\n",
    "\n",
    "    #print(soup.prettify())\n",
    "\n",
    "    rr=soup.p.contents[1]\n",
    "    rr=rr.contents[1]\n",
    "    #rr.contents\n",
    "    #Convert soup to unicode\n",
    "    unicode_string=str(rr)\n",
    "    #print(unicode_string)\n",
    "\n",
    "    #Find date indicies in email\n",
    "    date_found=re.search(r\"\\d\\d/\\d\\d/\\d\\d\",unicode_string) ## searching for date in message (this is a constant regular expression we can take advantage of) )'\n",
    "    date_found=np.asarray(date_found.span())\n",
    "    #print(date_found[0])\n",
    "\n",
    "    #grab date string\n",
    "    rr_dates=unicode_string[date_found[0]:date_found[1]]\n",
    "    rr_dates\n",
    "\n",
    "    #### Grab RRs From Email Message\n",
    "\n",
    "    #Find RR indicies in email\n",
    "    #print(unicode_string.find(\"Bullish\"))\n",
    "    #print(unicode_string.find(\"Hedgeye's Risk Ranges\"))\n",
    "\n",
    "\n",
    "    #grab rr string\n",
    "    rr_rrs=unicode_string[231:2063]\n",
    "    #print(type(rr_rrs))\n",
    "    rr_rrs\n",
    "\n",
    "    test_split = rr_rrs.split('\\r\\n')\n",
    "    test_split\n",
    "\n",
    "    test_series=pd.Series(test_split)\n",
    "    test_series.head()\n",
    "\n",
    "    ##Break out DataFrame Columns from Series Data\n",
    "    cols=test_series[2:3]\n",
    "    #print(cols)\n",
    "\n",
    "    header = [n.split(' ') for n in cols]\n",
    "    #print(header)\n",
    "\n",
    "    header_df=pd.DataFrame(header)\n",
    "    #print(header_df)\n",
    "\n",
    "    header_df.columns = header_df.iloc[0]\n",
    "\n",
    "    header_df=header_df.drop(header_df.index[0])\n",
    "\n",
    "    #print(header_df)\n",
    "\n",
    "    ##Grabbing the mislocated Trend value for implementation back into dataframe later on\n",
    "    trend_header=header_df.columns[-1]\n",
    "    #print(trend_header)\n",
    "    ##Grabbing the mislocated Security Name (UST10 YR) for implementation back into dataframe later on\n",
    "    sec_header=header_df.columns[-2]\n",
    "    #print(sec_header)\n",
    "\n",
    "    #### So we have some excess columns that we need to get rid of, and we also need to save this information into it's own dataframe b/c it is actually data, and not data attributes or descriptions\n",
    "\n",
    "    ### Drop excess columns \n",
    "\n",
    "    #### THIS CODE HAS APPENDEGAGES!!!!, if need to access old header_df, rerurn the code ABOVE THIS CELL\n",
    "    header_cols=[-1,-2]\n",
    "    header_df.drop(header_df.columns[header_cols],axis=1,inplace=True)\n",
    "    header_df\n",
    "\n",
    "    raw=test_series.reset_index(drop=True)\n",
    "    raw=raw[3:].reset_index(drop=True)\n",
    "    raw.head()\n",
    "\n",
    "    ## Replace (remove) spaces between indexes that do not work with regex logic (ie Russell 2000, Nikkei 225, SP 500, etc)\n",
    "    raw=raw.str.replace(r\"(?<=[liP]) (?=\\d)\",'') ## searching for first instances of '1 str' + ' ' + '1 int'\n",
    "    raw=raw.str.replace(r\"(?<=\\d) (?=[I])\",'') ## Regex specific to Nikkei 225 Index\n",
    "    raw.head()\n",
    "\n",
    "    ##Begin Splitting series for compatible DataFrame creation\n",
    "    raw = raw.str.split(r\"(?![a-z]) (?=\\d)\", expand=True)\n",
    "    raw.head()\n",
    "\n",
    "    squoze_raw = raw.iloc[:,-1:].squeeze()\n",
    "    #print(squoze_raw.head())\n",
    "\n",
    "    lrs=squoze_raw.str.split(r\"(?<=\\d) (?=[A-Z])\", expand=True)\n",
    "    lrs.tail()\n",
    "\n",
    "    squoze_lrs= lrs.iloc[:,-1:].squeeze()\n",
    "    #print(len(squoze_lrs))\n",
    "    squoze_lrs.tail()\n",
    "\n",
    "    final_split=squoze_lrs.str.split(r\"(?<=[A-Z]) (?=[(])\" , expand=True)\n",
    "    ticker_split = final_split.iloc[:,0]\n",
    "    ticker_split=ticker_split.reset_index(drop=True)\n",
    "    #print(len(ticker_split))\n",
    "    #print(ticker_split.tail())\n",
    "\n",
    "\n",
    "    trend_split=final_split.iloc[:,-1:]\n",
    "    trend_split=trend_split.reset_index(drop=True)\n",
    "    #print(len(trend_split))\n",
    "    #print(trend_split.tail())\n",
    "\n",
    "    ### Adding the Trend Value that was originally located in the df header\n",
    "\n",
    "    #Shift whole column down \n",
    "    trend_split=trend_split.shift(periods=1,axis=0)\n",
    "\n",
    "    #Add trend value to new empty cell\n",
    "    trend_split.iloc[0]=trend_header\n",
    "    trend_split.tail()\n",
    "\n",
    "    ### Adding the Ticker Value that was originally located in the df header\n",
    "\n",
    "    #Shift whole column down \n",
    "    ticker_split=ticker_split.shift(periods=1,axis=0)\n",
    "\n",
    "    #Add trend value to new empty cell\n",
    "    ticker_split.iloc[0]=sec_header\n",
    "    ticker_split.tail()\n",
    "\n",
    "    final_df = raw.assign(LastPrice = lrs[0])\n",
    "    final_df = final_df.assign(Trend = trend_split)\n",
    "    final_df = final_df.assign(Ticker = ticker_split)\n",
    "    final_df = final_df.drop([3], axis =1)\n",
    "    final_df= final_df.rename(columns={0: \"Asset\", 1: \"LERR\",2: \"TERR\"})\n",
    "    final_df['Date']=rr_dates\n",
    "\n",
    "    appended_data.append(final_df)\n",
    "rr_dfs = pd.concat(appended_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2074645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rr_df=rr_dfs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7b866ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Asset    LERR    TERR LastPrice      Trend  Ticker      Date\n",
      "0    10-Year U.S. Treasury Yield    1.78    1.63      1.67  (BULLISH)  UST10Y  04/12/21\n",
      "1     2-Year U.S. Treasury Yield    0.18    0.13      0.16  (BULLISH)   UST2Y  04/12/21\n",
      "2                     S&amp;P500   4,022   4,172     4,128  (BULLISH)     SPX  04/12/21\n",
      "3                    Russell2000   2,173   2,304     2,243  (BULLISH)     RUT  04/12/21\n",
      "4               NASDAQ Composite  13,122  14,152    13,900  (BULLISH)   COMPQ  04/12/21\n",
      "..                           ...     ...     ...       ...        ...     ...       ...\n",
      "913                  Amazon Inc.   3,019   3,214     3,057  (BEARISH)    AMZN  02/26/21\n",
      "914                Facebook Inc.     247     270       254  (BEARISH)      FB  02/26/21\n",
      "915                Alphabet Inc.   2,001   2,140     2,015  (BULLISH)   GOOGL  02/26/21\n",
      "916                 Netflix Inc.     531     565       546  (BULLISH)    NFLX  02/26/21\n",
      "917                   Tesla Inc.    644     None      None  (BEARISH)    TSLA  02/26/21\n",
      "\n",
      "[918 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(rr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af8b50",
   "metadata": {},
   "source": [
    "## SINGLE DATAFRAME LOAD in CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af06db3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=get_message(service,'me','177de7542c8d39ee')\n",
    "#print(test)\n",
    "\n",
    "## Beautiful Soup\n",
    "soup = BeautifulSoup(test, 'lxml')\n",
    "\n",
    "#print(soup.prettify())\n",
    "\n",
    "rr=soup.p.contents[1]\n",
    "rr=rr.contents[1]\n",
    "#rr.contents[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265c290",
   "metadata": {},
   "source": [
    "#### Grab Dates From Email Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e517ef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Convert soup to unicode\n",
    "unicode_string=str(rr)\n",
    "#print(unicode_string)\n",
    "\n",
    "#Find date indicies in email\n",
    "date_found=re.search(r\"\\d\\d/\\d\\d/\\d\\d\",unicode_string) ## searching for date in message (this is a constant regular expression we can take advantage of) )'\n",
    "date_found=np.asarray(date_found.span())\n",
    "#print(date_found[0])\n",
    "\n",
    "#grab date string\n",
    "rr_dates=unicode_string[date_found[0]:date_found[1]]\n",
    "#rr_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18fea5b",
   "metadata": {},
   "source": [
    "#### Grab RRs From Email Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a9f0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find RR indicies in email\n",
    "#print(unicode_string.find(\"Bullish\"))\n",
    "#print(unicode_string.find(\"Hedgeye's Risk Ranges\"))\n",
    "\n",
    "\n",
    "#grab rr string\n",
    "rr_rrs=unicode_string[231:2063]\n",
    "#print(type(rr_rrs))\n",
    "#rr_rrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "155151f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = rr_rrs.split('\\r\\n')\n",
    "#test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e462e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series=pd.Series(test_split)\n",
    "#test_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17ea5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Break out DataFrame Columns from Series Data\n",
    "cols=test_series[2:3]\n",
    "#print(cols)\n",
    "\n",
    "header = [n.split(' ') for n in cols]\n",
    "#print(header)\n",
    "\n",
    "header_df=pd.DataFrame(header)\n",
    "#print(header_df)\n",
    "\n",
    "header_df.columns = header_df.iloc[0]\n",
    "\n",
    "header_df=header_df.drop(header_df.index[0])\n",
    "\n",
    "#print(header_df)\n",
    "\n",
    "##Grabbing the mislocated Trend value for implementation back into dataframe later on\n",
    "trend_header=header_df.columns[-1]\n",
    "#print(trend_header)\n",
    "##Grabbing the mislocated Security Name (UST10 YR) for implementation back into dataframe later on\n",
    "sec_header=header_df.columns[-2]\n",
    "#print(sec_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0078c9",
   "metadata": {},
   "source": [
    "#### So we have some excess columns that we need to get rid of, and we also need to save this information into it's own dataframe b/c it is actually data, and not data attributes or descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b88c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop excess columns \n",
    "\n",
    "#### THIS CODE HAS APPENDEGAGES!!!!, if need to access old header_df, rerurn the code ABOVE THIS CELL\n",
    "header_cols=[-1,-2]\n",
    "header_df.drop(header_df.columns[header_cols],axis=1,inplace=True)\n",
    "#header_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f5433e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=test_series.reset_index(drop=True)\n",
    "raw=raw[3:].reset_index(drop=True)\n",
    "#raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7d59303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-207d894cc2c1>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  raw=raw.str.replace(r\"(?<=[liP]) (?=\\d)\",'') ## searching for first instances of '1 str' + ' ' + '1 int'\n",
      "<ipython-input-26-207d894cc2c1>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  raw=raw.str.replace(r\"(?<=\\d) (?=[I])\",'') ## Regex specific to Nikkei 225 Index\n"
     ]
    }
   ],
   "source": [
    "## Replace (remove) spaces between indexes that do not work with regex logic (ie Russell 2000, Nikkei 225, SP 500, etc)\n",
    "raw=raw.str.replace(r\"(?<=[liP]) (?=\\d)\",'') ## searching for first instances of '1 str' + ' ' + '1 int'\n",
    "raw=raw.str.replace(r\"(?<=\\d) (?=[I])\",'') ## Regex specific to Nikkei 225 Index\n",
    "#raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ca0e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Begin Splitting series for compatible DataFrame creation\n",
    "raw = raw.str.split(r\"(?![a-z]) (?=\\d)\", expand=True)\n",
    "#raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b458202",
   "metadata": {},
   "outputs": [],
   "source": [
    "squoze_raw = raw.iloc[:,-1:].squeeze()\n",
    "#print(squoze_raw.head())\n",
    "\n",
    "lrs=squoze_raw.str.split(r\"(?<=\\d) (?=[A-Z])\", expand=True)\n",
    "#lrs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d04ac9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "squoze_lrs= lrs.iloc[:,-1:].squeeze()\n",
    "#print(len(squoze_lrs))\n",
    "#squoze_lrs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82346baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_split=squoze_lrs.str.split(r\"(?<=[A-Z]) (?=[(])\" , expand=True)\n",
    "ticker_split = final_split.iloc[:,0]\n",
    "ticker_split=ticker_split.reset_index(drop=True)\n",
    "#print(len(ticker_split))\n",
    "#print(ticker_split.tail())\n",
    "\n",
    "\n",
    "trend_split=final_split.iloc[:,-1:]\n",
    "trend_split=trend_split.reset_index(drop=True)\n",
    "#print(len(trend_split))\n",
    "#print(trend_split.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d9580b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding the Trend Value that was originally located in the df header\n",
    "\n",
    "#Shift whole column down \n",
    "trend_split=trend_split.shift(periods=1,axis=0)\n",
    "\n",
    "#Add trend value to new empty cell\n",
    "trend_split.iloc[0]=trend_header\n",
    "#trend_split.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed2f014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding the Ticker Value that was originally located in the df header\n",
    "\n",
    "#Shift whole column down \n",
    "ticker_split=ticker_split.shift(periods=1,axis=0)\n",
    "\n",
    "#Add trend value to new empty cell\n",
    "ticker_split.iloc[0]=sec_header\n",
    "#ticker_split.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68ba0966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = raw.assign(LastPrice = lrs[0])\n",
    "\n",
    "final_df = final_df.assign(Trend = trend_split)\n",
    "final_df = final_df.assign(Ticker = ticker_split)\n",
    "\n",
    "final_df = final_df.drop([3], axis =1)\n",
    "final_df= final_df.rename(columns={0: \"Asset\", 1: \"LERR\",2: \"TERR\"})\n",
    "#final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "004a4a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asset</th>\n",
       "      <th>LERR</th>\n",
       "      <th>TERR</th>\n",
       "      <th>LastPrice</th>\n",
       "      <th>Trend</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Trend</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDEX BUY TRADE SELL TRADE PREV. CLOSE UST10Y ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-Year U.S. Treasury Yield</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.54</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-Year U.S. Treasury Yield</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>UST2Y</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S&amp;amp;P500</td>\n",
       "      <td>3,811</td>\n",
       "      <td>3,957</td>\n",
       "      <td>3,829</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>SPX</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Russell2000</td>\n",
       "      <td>1,980</td>\n",
       "      <td>2,301</td>\n",
       "      <td>2,200</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>RUT</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NASDAQ Composite</td>\n",
       "      <td>12,992</td>\n",
       "      <td>14,326</td>\n",
       "      <td>13,119</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>COMPQ</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Technology Select Sector SPDR Fund</td>\n",
       "      <td>129.96</td>\n",
       "      <td>140.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>XLK</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Energy Select Sector SPDR Fund</td>\n",
       "      <td>46.17</td>\n",
       "      <td>51.02</td>\n",
       "      <td>49.32</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>XLE</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Financials Select Sector SPDR Fund</td>\n",
       "      <td>31.39</td>\n",
       "      <td>33.81</td>\n",
       "      <td>32.94</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>XLF</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Utilities Select Sector SPDR Fund</td>\n",
       "      <td>58.56</td>\n",
       "      <td>61.28</td>\n",
       "      <td>59.46</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>XLU</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VanEck Vectors Gold Miners ETF</td>\n",
       "      <td>31.60</td>\n",
       "      <td>34.45</td>\n",
       "      <td>32.33</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>GDX</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shanghai Composite</td>\n",
       "      <td>3,473</td>\n",
       "      <td>3,720</td>\n",
       "      <td>3,509</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>SSEC</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nikkei225Index</td>\n",
       "      <td>28,906</td>\n",
       "      <td>30,652</td>\n",
       "      <td>28,966</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>NIKK</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>German DAX Composite</td>\n",
       "      <td>13,718</td>\n",
       "      <td>14,140</td>\n",
       "      <td>13,879</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>DAX</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Volatility Index</td>\n",
       "      <td>17.80</td>\n",
       "      <td>30.99</td>\n",
       "      <td>28.89</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>VIX</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>U.S. Dollar Index</td>\n",
       "      <td>89.71</td>\n",
       "      <td>90.90</td>\n",
       "      <td>90.14</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>USD</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Euro to U.S. Dollar</td>\n",
       "      <td>1.205</td>\n",
       "      <td>1.223</td>\n",
       "      <td>1.218</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>EUR/USD</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>U.S. Dollar to Japanese Yen</td>\n",
       "      <td>104.89</td>\n",
       "      <td>106.49</td>\n",
       "      <td>106.21</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>USD/JPY</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>British Pound to U.S. Dollar</td>\n",
       "      <td>1.383</td>\n",
       "      <td>1.421</td>\n",
       "      <td>1.401</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>GBP/USD</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Canadian Dollar to U.S. Dollar</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>CAD/USD</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>U.S. Dollar to Swiss Franc</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>USD/CHF</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Light Crude Oil Spot Price</td>\n",
       "      <td>58.41</td>\n",
       "      <td>64.14</td>\n",
       "      <td>63.53</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>WTIC</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Natural Gas Spot Price</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.78</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>NATGAS</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gold Spot Price</td>\n",
       "      <td>1,748</td>\n",
       "      <td>1,818</td>\n",
       "      <td>1,775</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Copper Spot Price</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.26</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>COPPER</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Silver Spot Price</td>\n",
       "      <td>26.49</td>\n",
       "      <td>28.20</td>\n",
       "      <td>27.68</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Microsoft Corp.</td>\n",
       "      <td>226</td>\n",
       "      <td>250</td>\n",
       "      <td>228</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>118</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Amazon Inc.</td>\n",
       "      <td>3,019</td>\n",
       "      <td>3,214</td>\n",
       "      <td>3,057</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Facebook Inc.</td>\n",
       "      <td>247</td>\n",
       "      <td>270</td>\n",
       "      <td>254</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>FB</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>2,001</td>\n",
       "      <td>2,140</td>\n",
       "      <td>2,015</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Netflix Inc.</td>\n",
       "      <td>531</td>\n",
       "      <td>565</td>\n",
       "      <td>546</td>\n",
       "      <td>(BULLISH)</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tesla Inc.</td>\n",
       "      <td>644</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>(BEARISH)</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>02/26/21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Asset    LERR    TERR LastPrice      Trend   Ticker      Date\n",
       "0                                                        None    None      None      Trend  Neutral  02/26/21\n",
       "1   INDEX BUY TRADE SELL TRADE PREV. CLOSE UST10Y ...    None    None      None       None     None  02/26/21\n",
       "2                         10-Year U.S. Treasury Yield    1.56    1.22      1.54       None     None  02/26/21\n",
       "3                          2-Year U.S. Treasury Yield    0.18    0.12      0.17  (BULLISH)    UST2Y  02/26/21\n",
       "4                                          S&amp;P500   3,811   3,957     3,829  (BULLISH)      SPX  02/26/21\n",
       "5                                         Russell2000   1,980   2,301     2,200  (BULLISH)      RUT  02/26/21\n",
       "6                                    NASDAQ Composite  12,992  14,326    13,119  (BULLISH)    COMPQ  02/26/21\n",
       "7                  Technology Select Sector SPDR Fund  129.96  140.15    130.00  (BULLISH)      XLK  02/26/21\n",
       "8                      Energy Select Sector SPDR Fund   46.17   51.02     49.32  (BULLISH)      XLE  02/26/21\n",
       "9                  Financials Select Sector SPDR Fund   31.39   33.81     32.94  (BULLISH)      XLF  02/26/21\n",
       "10                  Utilities Select Sector SPDR Fund   58.56   61.28     59.46  (BEARISH)      XLU  02/26/21\n",
       "11                     VanEck Vectors Gold Miners ETF   31.60   34.45     32.33  (BEARISH)      GDX  02/26/21\n",
       "12                                 Shanghai Composite   3,473   3,720     3,509  (BULLISH)     SSEC  02/26/21\n",
       "13                                     Nikkei225Index  28,906  30,652    28,966  (BULLISH)     NIKK  02/26/21\n",
       "14                               German DAX Composite  13,718  14,140    13,879  (BULLISH)      DAX  02/26/21\n",
       "15                                   Volatility Index   17.80   30.99     28.89  (BEARISH)      VIX  02/26/21\n",
       "16                                  U.S. Dollar Index   89.71   90.90     90.14  (BEARISH)      USD  02/26/21\n",
       "17                                Euro to U.S. Dollar   1.205   1.223     1.218  (BULLISH)  EUR/USD  02/26/21\n",
       "18                        U.S. Dollar to Japanese Yen  104.89  106.49    106.21  (BULLISH)  USD/JPY  02/26/21\n",
       "19                       British Pound to U.S. Dollar   1.383   1.421     1.401  (BULLISH)  GBP/USD  02/26/21\n",
       "20                     Canadian Dollar to U.S. Dollar    0.79    0.80      0.79  (BULLISH)  CAD/USD  02/26/21\n",
       "21                         U.S. Dollar to Swiss Franc    0.88    0.91      0.90  (BEARISH)  USD/CHF  02/26/21\n",
       "22                         Light Crude Oil Spot Price   58.41   64.14     63.53  (BULLISH)     WTIC  02/26/21\n",
       "23                             Natural Gas Spot Price    2.65    3.24      2.78  (BULLISH)   NATGAS  02/26/21\n",
       "24                                    Gold Spot Price   1,748   1,818     1,775  (BEARISH)     GOLD  02/26/21\n",
       "25                                  Copper Spot Price    3.99    4.43      4.26  (BULLISH)   COPPER  02/26/21\n",
       "26                                  Silver Spot Price   26.49   28.20     27.68  (BULLISH)   SILVER  02/26/21\n",
       "27                                    Microsoft Corp.     226     250       228  (BULLISH)     MSFT  02/26/21\n",
       "28                                         Apple Inc.     118     130       120  (BEARISH)     AAPL  02/26/21\n",
       "29                                        Amazon Inc.   3,019   3,214     3,057  (BEARISH)     AMZN  02/26/21\n",
       "30                                      Facebook Inc.     247     270       254  (BEARISH)       FB  02/26/21\n",
       "31                                      Alphabet Inc.   2,001   2,140     2,015  (BULLISH)    GOOGL  02/26/21\n",
       "32                                       Netflix Inc.     531     565       546  (BULLISH)     NFLX  02/26/21\n",
       "33                                         Tesla Inc.    644     None      None  (BEARISH)     TSLA  02/26/21"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['Date']=rr_dates\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c651c99",
   "metadata": {},
   "source": [
    "From here, these ranges can be grabbed daily and uploaded to a csv or excel file. The process of loading is not included in this repository because the same logic is in another one of my repositories and I wanted to get this out quickly for the #HedgeyeNation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1c6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
